{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b487b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f18c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\adity\\Desktop\\gemma\\interview_questions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f900a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>Q. How do you maintain company coding standards?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCS</td>\n",
       "      <td>Q. Explain the Python installation process.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCS</td>\n",
       "      <td>Q. Explain OOP concepts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCS</td>\n",
       "      <td>Q. What is DevOps?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCS</td>\n",
       "      <td>Q. Write a Python code to reverse the last k d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company                                           Question\n",
       "0     TCS   Q. How do you maintain company coding standards?\n",
       "1     TCS        Q. Explain the Python installation process.\n",
       "2     TCS                           Q. Explain OOP concepts.\n",
       "3     TCS                                 Q. What is DevOps?\n",
       "4     TCS  Q. Write a Python code to reverse the last k d..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5019ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_9232\\392820014.py:14: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "c:\\Users\\adity\\Desktop\\gemma\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS index created and saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optional: Filter out empty questions\n",
    "df = df[df[\"Question\"].notna()]\n",
    "\n",
    "# Convert each question to a LangChain Document object\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=row[\"Question\"],\n",
    "        metadata={\"company\": row[\"Company\"]}\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# Initialize embedding model (MiniLM)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create FAISS index from documents\n",
    "faiss_index = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# Save FAISS index to disk\n",
    "faiss_index.save_local(\"faiss_index_interview_questions\")\n",
    "print(\"FAISS index created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e809697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company details FAISS index saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"top_companies.csv\")\n",
    "\n",
    "# Combine fields into a text string\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    content = f\"\"\"\n",
    "    Company: {row['Company']}\n",
    "    Rating: {row.get('Rating', 'N/A')}\n",
    "    Reviews: {row.get('Reviews', 'N/A')}\n",
    "    Industry & Location: {row.get('Industry & Location', 'N/A')}\n",
    "    \"\"\"\n",
    "    documents.append(Document(page_content=content.strip(), metadata={\"company\": row[\"Company\"]}))\n",
    "\n",
    "# Embedding model\n",
    "embedder = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create and save FAISS index\n",
    "company_faiss = FAISS.from_documents(documents, embedder)\n",
    "company_faiss.save_local(\"faiss_index_company_details\")\n",
    "print(\"Company details FAISS index saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8952debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. What is SDLC?\n",
      "Q. Explain what SDLC is.\n",
      "Q. What is SDLC and what are its types?\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "faiss_index = FAISS.load_local(\n",
    "    \"faiss_index_interview_questions\",\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True  # ðŸ‘ˆ this allows pickle loading\n",
    ")\n",
    "\n",
    "\n",
    "# Retrieve top 3 similar questions\n",
    "retriever = faiss_index.as_retriever(search_kwargs={\"k\": 3})\n",
    "results = retriever.get_relevant_documents(\"What is SDLC?\")\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e67828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"interview_questions.csv\")\n",
    "df = df.drop_duplicates(subset=[\"Question\"])  # Remove duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68997e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. What is SDLC?\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(\"What is SDLC?\")\n",
    "unique_contents = list(set([doc.page_content for doc in retrieved_docs]))\n",
    "\n",
    "for content in unique_contents:\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a04d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Create documents\n",
    "docs = [Document(page_content=q) for q in df['Question']]\n",
    "\n",
    "# Initialize embedding model\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create and save index\n",
    "faiss_index = FAISS.from_documents(docs, embedder)\n",
    "faiss_index.save_local(\"faiss_index_interview_questions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513fcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
